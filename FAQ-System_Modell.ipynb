{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOnfHBGM1VL//245LKp+D/Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Neuer Abschnitt"],"metadata":{"id":"h7HsqJGWWkah"}},{"cell_type":"code","source":["# Die Pandas-Bibliothek wird hier als \"pd\" importiert.\n","# Pandas ist eine leistungsstarke Bibliothek zur Datenverarbeitung und -analyse. Sie erleichtert\n","# das Laden, Bearbeiten und Speichern von tabellenartigen Daten, z. B. aus CSV-Dateien.\n","import pandas as pd\n","\n","# Die Transformers-Bibliothek bietet eine Sammlung vortrainierter Modelle für verschiedene NLP-Aufgaben,\n","# wie Textklassifikation, Textgenerierung und Übersetzung. Hier wird speziell die \"pipeline\"-Funktion importiert,\n","# die eine vereinfachte Möglichkeit bietet, vortrainierte Modelle zu verwenden.\n","from transformers import pipeline\n","\n","# NLTK (Natural Language Toolkit) ist eine Bibliothek zur Sprachverarbeitung, die eine Vielzahl an\n","# Tools und Datensätzen für natürliche Sprachverarbeitung (Natural Language Processing, NLP) enthält,\n","# wie z. B. Tokenizer, Wortlisten und Korpora.\n","import nltk\n","\n","# Die Module `DataLoader` und `Dataset` aus `torch.utils.data` dienen zur Handhabung von Datensätzen.\n","# \"Dataset\" bietet eine Standardmethode zur Definition eines Datensatzes, während \"DataLoader\" Funktionen\n","# zum effizienten Laden, Shuffeln und Batchen der Daten bereitstellt. Diese Module sind zentral für das Training von Modellen.\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Die PyTorch-Bibliothek wird hier importiert, die eine der populärsten Bibliotheken für Deep Learning ist.\n","# Sie bietet grundlegende Werkzeuge für die Arbeit mit neuronalen Netzen, Tensoren und GPU-unterstütztem Rechnen.\n","import torch\n","\n","# Hier werden Module für neuronale Netzwerke und die Optimierung in PyTorch importiert.\n","# `torch.nn` enthält Bausteine für den Aufbau neuronaler Netze,\n","# während `torch.optim` Werkzeuge für die Optimierung von Gewichten im Trainingsprozess bereitstellt.\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# `LabelEncoder` wird aus sklearn.preprocessing importiert.\n","# Dieser Encoder wird verwendet, um kategorische Labels (z.B. \"positive\", \"negative\") in numerische Werte umzuwandeln,\n","# da maschinelle Lernmodelle nur numerische Daten verarbeiten können.\n","from sklearn.preprocessing import LabelEncoder\n","\n","# `train_test_split` aus `sklearn.model_selection` trennt die Daten in Trainings- und Testdatensätze.\n","# Dies ist eine Standardtechnik, um die Modellleistung zu testen und Überanpassung (Overfitting) zu vermeiden.\n","from sklearn.model_selection import train_test_split\n","\n","# Die Funktion `pad` aus `torch.nn.functional` wird importiert. Sie dient dazu, Eingaben mit unterschiedlicher Länge\n","# auf eine einheitliche Länge zu bringen, indem sie am Ende der Sequenzen Padding-Zeichen einfügt.\n","# Dies ist besonders nützlich für Textdaten, da diese in der Regel variierende Längen aufweisen.\n","from torch.nn.functional import pad\n","\n","# `BertForSequenceClassification` ist ein vortrainiertes BERT-Modell aus der Transformers-Bibliothek,\n","# das speziell für Klassifikationsaufgaben angepasst ist. Es kann verwendet werden, um Textsequenzen\n","# in Kategorien einzuordnen, nachdem es auf spezifische Daten trainiert wurde.\n","from transformers import BertForSequenceClassification\n","\n","# Der `BertTokenizer` wird verwendet, um Eingabetexte in Token umzuwandeln, die das Modell verstehen kann.\n","# Tokenizer teilen Text in einzelne Bestandteile (Tokens) auf und konvertieren sie in IDs,\n","# die als Eingabe für das BERT-Modell dienen.\n","from transformers import BertTokenizer\n","\n","# Import des BERT-Modells und des Tokenizers aus der Transformers-Bibliothek\n","# `BertModel` ist das BERT-Sprachmodell, das kontextuelle Darstellungen von Text erstellt.\n","# `BertTokenizer` konvertiert Texte in Token und Token-IDs, die BERT als Eingabe verarbeitet.\n","from transformers import BertModel, BertTokenizer\n","\n","# Installation der benötigten Bibliotheken\n","!pip install transformers\n","\n","# Download von NLTK-Ressourcen\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","# Laden der notwendigen Python Bibliotheken, um mit Datensatz aus Github zu arbeiten\n","import os\n","import requests\n","import pandas as pd\n","\n","# Festlegen des aktuellen Verzeichnisses\n","current_directory = os.getcwd()\n","\n","# URL der manuell annotierten FAQs-Liste auf GitHub\n","# file_url = \"https://raw.githubusercontent.com/username/repo/main/FAQs-Liste.csv\"\n","# Hinweis: Ersetzen Sie die URL mit der tatsächlichen URL Ihrer FAQs-Liste auf GitHub\n","\n","file_name = \"FAQs - Liste.xlsx\"\n","\n","# Die FAQs-Liste von GitHub herunterladen und lokal speichern\n","# response = requests.get(file_url)\n","# with open(file_name, \"wb\") as file:\n","# file.write(response.content)\n","\n","# Datei in ein Pandas DataFrame laden\n","# Anpassung der Einleseparameter basierend auf dem Format Ihrer CSV-Datei\n","\n","\n","# Anzeigen der geladenen Daten\n","\n","# Prüfen, ob die benötigten Spalten vorhanden sind\n","required_columns = ['Frage', 'Antwort', 'Thema']\n","\n","df = pd.read_excel(file_name, engine='openpyxl', usecols=required_columns)\n","df = df.dropna(subset=required_columns)\n","print(df.head())\n","\n","def split_by_topic(df, test_samples_per_topic=2, random_state=42):\n","    train_df = pd.DataFrame()\n","    test_df = pd.DataFrame()\n","    for topic in df['Thema'].unique():\n","        topic_df = df[df['Thema'] == topic]\n","        topic_test_df = topic_df.sample(n=test_samples_per_topic, random_state=random_state)\n","        topic_train_df = topic_df.drop(topic_test_df.index)\n","        train_df = pd.concat([train_df, topic_train_df])\n","        test_df = pd.concat([test_df, topic_test_df])\n","    return train_df, test_df\n","\n","# Aufteilen der Daten in Trainings- und Testdaten\n","train_df, test_df = split_by_topic(df, test_samples_per_topic=2, random_state=42)\n","\n","# Hier eine Funktion schreiben die beispielsweise Testdaten trennt - das heißt von jeder Frage nehme ich 2 für Test und 9 Fragen für Training\n","\n","# Frage: Validation ist hoch, und Loss war niedrig - ist kein gutes Zeichn wenn Validation hoch ist aber Loss niedrig das zeigt eigentlich alles ist gut\n","\n","# Festlegen der GPU oder CPU für das Training\n","device = torch.device('cuda')\n","# Definition der MultiTaskBERTClassifier-Klasse\n","class MultiTaskBERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_size=768, num_answer_labels=10, num_category_labels=5):\n","        super(MultiTaskBERTClassifier, self).__init__()\n","\n","        # Übernimmt das übergebene BERT-Modell als Basismodell für die Textrepräsentation\n","        self.bert = bert_model\n","\n","        # Answer prediction head\n","        # Ein Klassifikator für die Vorhersage von Antwortkategorien\n","        self.answer_classifier = nn.Sequential(\n","            nn.Linear(hidden_size, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(128, num_answer_labels)\n","        )\n","\n","        # Category prediction head\n","        # Ein Klassifikator für die Vorhersage der Themenkategorie\n","        self.category_classifier = nn.Sequential(\n","            nn.Linear(hidden_size, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(128, num_category_labels)\n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        # Extrahieren der CLS-Token-Darstellung\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        cls_token = outputs.last_hidden_state[:, 0, :]  # Repräsentation des CLS-Tokens\n","\n","        # Weitergabe durch Klassifikator-Köpfe\n","        answer_logits = self.answer_classifier(cls_token)\n","        category_logits = self.category_classifier(cls_token)\n","\n","        return answer_logits, category_logits\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fP1_1XB4bcVj","executionInfo":{"status":"ok","timestamp":1742365809927,"user_tz":-60,"elapsed":2671,"user":{"displayName":"Naima Grebe","userId":"04373729895907398022"}},"outputId":"a4baeae7-02e3-42dc-ce83-4816349b5067"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n","  warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["             Thema                                              Frage  \\\n","1  Einkommensteuer        Muss ich den Original-Bescheid aufbewahren?   \n","2  Einkommensteuer            Muss ich den Originalbescheid behalten?   \n","3  Einkommensteuer  Ist es erforderlich, den Originalbescheid aufz...   \n","4  Einkommensteuer   Soll ich den Originalbescheid lange aufbewahren?   \n","5  Einkommensteuer  Muss ich den Originalbescheid für immer aufbew...   \n","\n","    Antwort  \n","1  §257 HGB  \n","2  §257 HGB  \n","3  §257 HGB  \n","4  §257 HGB  \n","5  §257 HGB  \n"]}]},{"cell_type":"code","source":["# Initialisierung des BERT-Modells und des Tokenizers\n","model_name = 'bert-base-german-cased'\n","bert_model = BertModel.from_pretrained(model_name)\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","\n","# Bestimmen der Anzahl von Antwort- und Kategorielabels\n","num_answer_labels = len(train_df['Antwort'].unique())\n","num_category_labels = len(train_df['Thema'].unique())\n","\n","# Initialisierung des Multi-Task-Klassifikators\n","model = MultiTaskBERTClassifier(\n","    bert_model,\n","    hidden_size=768,\n","    num_answer_labels=num_answer_labels,\n","    num_category_labels=num_category_labels\n",").to(device)\n","\n","# Definition der QADataset-Klasse\n","class QADataset(Dataset):\n","    def __init__(self, data, tokenizer, max_len=200):\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","        # Extrahieren der Fragen, Antworten und Kategorien aus dem DataFrame\n","        self.questions = data['Frage'].tolist()\n","        self.responses = data['Antwort'].tolist()\n","        self.categories = data['Thema'].tolist()\n","\n","        # Initialisierung der LabelEncoder für Antworten und Kategorien\n","        self.response_encoder = LabelEncoder()\n","        self.category_encoder = LabelEncoder()\n","\n","        # Umwandeln der Antworten und Kategorien in numerische Labels\n","        self.response_labels = self.response_encoder.fit_transform(self.responses)\n","        self.category_labels = self.category_encoder.fit_transform(self.categories)\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        question = self.questions[idx]\n","        response_label = self.response_labels[idx]\n","        category_label = self.category_labels[idx]\n","\n","        # Tokenisierung der Frage mit dem BERT-Tokenizer\n","        encoding = self.tokenizer.encode_plus(\n","            question,\n","            truncation=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_tensors='pt'\n","        )\n","        input_ids = encoding['input_ids'].squeeze()\n","        attention_mask = encoding['attention_mask'].squeeze()\n","\n","        # Rückgabe der tokenisierten Frage und der Labels als Tensoren\n","        return input_ids, attention_mask, torch.tensor(response_label, dtype=torch.long), torch.tensor(category_label, dtype=torch.long)\n","\n","# Erstellen der Datasets und DataLoader für Training und Test\n","train_dataset = QADataset(train_df, tokenizer)\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","\n","test_dataset = QADataset(test_df, tokenizer)\n","test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n","\n","# Definition der Verlustfunktionen\n","criterion_answer = nn.CrossEntropyLoss()\n","criterion_category = nn.CrossEntropyLoss()\n","\n","# Initialisierung des Optimierers\n","optimizer = optim.Adam(model.parameters(), lr=1e-5) # vorher 2le-5 Hyperparameter Anpassung\n","\n","# Trainingsfunktion\n","def train_multi_task_model(model, dataloader, criterion_answer, criterion_category, optimizer, num_epochs=3):\n","    model.train()  # Setzt das Modell in den Trainingsmodus\n","\n","    for epoch in range(num_epochs):\n","        epoch_loss = 0\n","        correct_answers = 0\n","        correct_categories = 0\n","        total = 0\n","\n","        for batch in dataloader:\n","            input_ids, attention_mask, answer_labels, category_labels = batch\n","            input_ids = input_ids.to(device)\n","            attention_mask = attention_mask.to(device)\n","            answer_labels = answer_labels.to(device)\n","            category_labels = category_labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Vorwärtsdurchlauf\n","            answer_outputs, category_outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","            # Verlustberechnung\n","            loss_answer = criterion_answer(answer_outputs, answer_labels)\n","            loss_category = criterion_category(category_outputs, category_labels)\n","            loss = loss_answer + loss_category\n","\n","            # Backward-Pass\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","\n","            # Berechnen der Genauigkeit\n","            _, predicted_answers = torch.max(answer_outputs, 1)\n","            _, predicted_categories = torch.max(category_outputs, 1)\n","\n","            total += answer_labels.size(0)\n","            correct_answers += (predicted_answers == answer_labels).sum().item()\n","            correct_categories += (predicted_categories == category_labels).sum().item()\n","\n","        # Genauigkeit für die Epoche berechnen\n","        epoch_answer_accuracy = correct_answers / total\n","        epoch_category_accuracy = correct_categories / total\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}, Answer Accuracy: {epoch_answer_accuracy:.4f}, Category Accuracy: {epoch_category_accuracy:.4f}\")\n","\n","    return model\n","\n","\n","# Training des Modells durchführen\n","print(\"Starte Training...\")\n","model = train_multi_task_model(model, train_loader, criterion_answer, criterion_category, optimizer, num_epochs=10) # Hier vorher 20\n","\n","# Evaluationsfunktion\n","def evaluate_multi_task_model(model, dataloader, criterion_answer, criterion_category):\n","    model.eval()  # Setzt das Modell in den Evaluationsmodus\n","    eval_loss = 0\n","    correct_answers = 0\n","    correct_categories = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids, attention_mask, answer_labels, category_labels = batch\n","            input_ids = input_ids.to(device)\n","            attention_mask = attention_mask.to(device)\n","            answer_labels = answer_labels.to(device)\n","            category_labels = category_labels.to(device)\n","\n","            # Vorwärtsdurchlauf\n","            answer_outputs, category_outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","            # Verlustberechnung\n","            loss_answer = criterion_answer(answer_outputs, answer_labels)\n","            loss_category = criterion_category(category_outputs, category_labels)\n","            loss = loss_answer + loss_category\n","            eval_loss += loss.item()\n","\n","            # Berechnen der Genauigkeit\n","            _, predicted_answers = torch.max(answer_outputs, 1)\n","            _, predicted_categories = torch.max(category_outputs, 1)\n","\n","            total += answer_labels.size(0)\n","            correct_answers += (predicted_answers == answer_labels).sum().item()\n","            correct_categories += (predicted_categories == category_labels).sum().item()\n","\n","    # Ausgabe der Evaluationsergebnisse\n","    avg_loss = eval_loss / len(dataloader)\n","    answer_accuracy = correct_answers / total\n","    category_accuracy = correct_categories / total\n","    print(f\"Validation Loss: {avg_loss:.4f}, Answer Accuracy: {answer_accuracy:.4f}, Category Accuracy: {category_accuracy:.4f}\")\n","\n","    return answer_accuracy, category_accuracy\n","\n","# Evaluation des trainierten Modells\n","print(\"Evaluiere Modell...\")\n","answer_accuracy, category_accuracy = evaluate_multi_task_model(model, test_loader, criterion_answer, criterion_category)\n","\n","# Speichern der LabelEncoder für spätere Vorhersagen\n","# Erstelle neue LabelEncoder-Instanzen und trainiere sie mit allen verfügbaren Daten\n","label_encoder_answer = LabelEncoder()\n","label_encoder_answer.fit(df['Antwort'].unique())\n","\n","label_encoder_category = LabelEncoder()\n","label_encoder_category.fit(df['Thema'].unique())\n","\n","# Mapping der Themenkategorien zu Mitarbeitern\n","mitarbeiter_map = {\n","    'Lohn': 'Alexandra Himmelreich',\n","    'EDV': 'Luke Horchler',\n","    'FiBu': 'Sven Althaus',\n","    'Unternehmensberatung': 'Stephan Sonneborn'\n","}\n","\n","# Funktion zur Vorhersage mit Unsicherheitsbehandlung\n","def predict_and_handle_uncertainty(model, question, true_answer=\"\", true_category=\"\", threshold=0.4):\n","    model.eval()\n","    encoding = tokenizer.encode_plus(\n","        question,\n","        truncation=True,\n","        max_length=200,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","    input_ids = encoding['input_ids'].to(device)\n","    attention_mask = encoding['attention_mask'].to(device)\n","\n","    with torch.no_grad():\n","        # Vorhersage durchführen\n","        answer_logits, category_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        # Softmax-Wahrscheinlichkeiten berechnen\n","        answer_probs = torch.softmax(answer_logits, dim=1)\n","        category_probs = torch.softmax(category_logits, dim=1)\n","\n","        # Maximale Wahrscheinlichkeit und zugehörigen Index bestimmen\n","        answer_confidence, answer_pred = torch.max(answer_probs, dim=1)\n","        category_confidence, category_pred = torch.max(category_probs, dim=1)\n","\n","    # Vorhersagen in lesbare Ausgaben umwandeln\n","    if answer_confidence.item() < threshold:\n","        answer_pred_label = \"Unable to provide a confident answer:\", label_encoder_answer.inverse_transform(answer_pred.cpu().numpy())[0]\n","    else:\n","        answer_pred_label = label_encoder_answer.inverse_transform(answer_pred.cpu().numpy())[0]\n","\n","    if category_confidence.item() < threshold:\n","        category_pred_label = \"Unable to determine category\"\n","    else:\n","        category_pred_label = label_encoder_category.inverse_transform(category_pred.cpu().numpy())[0]\n","\n","    # Ausgabe der Vorhersageergebnisse\n","    print(f\"Predicted Answer: {answer_pred_label}\")\n","    print(f\"Predicted Category: {category_pred_label}\")\n","\n","    if true_answer and true_category:\n","        print(f\"Correct Answer: {true_answer}\")\n","        print(f\"Correct Category: {true_category}\")\n","\n","    print(f\"Answer Prediction Confidence: {answer_confidence.item()}\")\n","    print(f\"Category Prediction Confidence: {category_confidence.item()}\")\n","\n","    # Entscheidung über die Ausgabe basierend auf Konfidenzwerten\n","    message = \"\"\n","    if answer_confidence.item() < threshold and category_confidence.item() < threshold:\n","        message = \"Leider kann ich das nicht bestimmen. Bitte wenden Sie sich an unser Support-Team für Unterstützung.\"\n","    elif answer_confidence.item() < threshold and category_confidence.item() >= threshold:\n","        if category_pred_label in mitarbeiter_map:\n","            message = f\"Bitte wenden Sie sich an {mitarbeiter_map[category_pred_label]}!\"\n","        else:\n","            message = \"Leider kann ich das nicht bestimmen. Bitte wenden Sie sich an unser Support-Team für Unterstützung.\"\n","    else:\n","        message = answer_pred_label\n","\n","    print(message + \"\\n\")\n","    return message\n","\n","# Beispielhafte Vorhersagen\n","print(\"\\nBeispielhafte Vorhersagen:\")\n","\n","# Speichern des trainierten Modells\n","torch.save({\n","    'model_state_dict': model.state_dict(),\n","    'optimizer_state_dict': optimizer.state_dict(),\n","    'num_answer_labels': num_answer_labels,\n","    'num_category_labels': num_category_labels\n","}, 'faq_model.pth')\n","\n","print(\"Modell gespeichert.\")\n","\n","# Speichern der LabelEncoder\n","import pickle\n","with open('label_encoder_answer.pkl', 'wb') as f:\n","    pickle.dump(label_encoder_answer, f)\n","with open('label_encoder_category.pkl', 'wb') as f:\n","    pickle.dump(label_encoder_category, f)\n","\n","print(\"LabelEncoder gespeichert.\")\n","\n","# Beispielhafte Vorhersagen\n","question = \"Was ist bei Einstellung eines Werksstudenten zu beachten?\"\n","predict_and_handle_uncertainty(model, question,\"Werkstudenten, die neben ihrem Studium arbeiten, sind in der Regel versicherungsfrei in der Kranken-, Pflege- und Arbeitslosenversicherung, wenn sie in der vorlesungsfreien Zeit nicht mehr als 20 Stunden pro Woche arbeiten. Sie sind jedoch in der Rentenversicherung pflichtversichert. Lohnsteuerrechtlich sollte die Besteuerung nach der Lohnsteuerkarte des Studenten erfolgen, und der Student muss sich selbst um eine studentische Krankenversicherung kümmern.\", \"Lohn\")\n","\n","question = \"Was ist ein Unternehmens-Check?\"\n","predict_and_handle_uncertainty(model, question, \"Der L&P Unternehmens-Check ist der Einstieg in ein präzises Analyse- und Steuerungssystem für deinen Betrieb. Verbinde eine Standortbestimmung durch die Spezialisten von Lückel & Partner mit der Einführung digitaler Prozesse in deinem Unternehmen. Spezialisten liefern verständliche und aussagekräftige Zahlen und begleiten dich für einen nachhaltigen Erfolg in deinem Unternehmen. https://www.lup-beratung.de/unternehmens-check-holzbau\", \"Unternehmensberatung\")\n","\n","question = \"Darf der Urlaub im Bauhauptgewerbe bei Austritt an den Arbeitnehmer ausgezahlt werden?\"\n","predict_and_handle_uncertainty(model, question, \"Nein, der Urlaub wird mitgenommen zum neuen Arbeitgeber. Sollte der Mitarbeiter nicht mehr im Baugewerbe tätig werden, kann er nach 3 Monaten die Urlaubsabgeltung bei der Soka-Bau beantragen.\", \"Lohn\")\n","\n","print(\"Fertig.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cAIf2PUMt8Q5","executionInfo":{"status":"ok","timestamp":1742367531822,"user_tz":-60,"elapsed":416142,"user":{"displayName":"Naima Grebe","userId":"04373729895907398022"}},"outputId":"42743fa1-f877-4833-b21e-2cd46c988896"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starte Training...\n","Epoch [1/10], Loss: 5.7184, Answer Accuracy: 0.0288, Category Accuracy: 0.6224\n","Epoch [2/10], Loss: 4.6916, Answer Accuracy: 0.1416, Category Accuracy: 0.9327\n","Epoch [3/10], Loss: 4.0511, Answer Accuracy: 0.3129, Category Accuracy: 0.9843\n","Epoch [4/10], Loss: 3.4114, Answer Accuracy: 0.5830, Category Accuracy: 0.9939\n","Epoch [5/10], Loss: 2.7877, Answer Accuracy: 0.7622, Category Accuracy: 0.9956\n","Epoch [6/10], Loss: 2.2374, Answer Accuracy: 0.8907, Category Accuracy: 0.9974\n","Epoch [7/10], Loss: 1.7588, Answer Accuracy: 0.9510, Category Accuracy: 0.9991\n","Epoch [8/10], Loss: 1.3855, Answer Accuracy: 0.9694, Category Accuracy: 0.9991\n","Epoch [9/10], Loss: 1.0957, Answer Accuracy: 0.9755, Category Accuracy: 0.9991\n","Epoch [10/10], Loss: 0.8741, Answer Accuracy: 0.9851, Category Accuracy: 0.9991\n","Evaluiere Modell...\n","Validation Loss: 6.3234, Answer Accuracy: 0.0000, Category Accuracy: 1.0000\n","\n","Beispielhafte Vorhersagen:\n","Modell gespeichert.\n","LabelEncoder gespeichert.\n","Predicted Answer: Werkstudenten, die neben ihrem Studium arbeiten, sind in der Regel versicherungsfrei in der Kranken-, Pflege- und Arbeitslosenversicherung, wenn sie in der vorlesungsfreien Zeit nicht mehr als 20 Stunden pro Woche arbeiten. Sie sind jedoch in der Rentenversicherung pflichtversichert. Lohnsteuerrechtlich sollte die Besteuerung nach der Lohnsteuerkarte des Studenten erfolgen, und der Student muss sich selbst um eine studentische Krankenversicherung kümmern.\n","Predicted Category: Lohn\n","Correct Answer: Werkstudenten, die neben ihrem Studium arbeiten, sind in der Regel versicherungsfrei in der Kranken-, Pflege- und Arbeitslosenversicherung, wenn sie in der vorlesungsfreien Zeit nicht mehr als 20 Stunden pro Woche arbeiten. Sie sind jedoch in der Rentenversicherung pflichtversichert. Lohnsteuerrechtlich sollte die Besteuerung nach der Lohnsteuerkarte des Studenten erfolgen, und der Student muss sich selbst um eine studentische Krankenversicherung kümmern.\n","Correct Category: Lohn\n","Answer Prediction Confidence: 0.42579302191734314\n","Category Prediction Confidence: 0.9202413558959961\n","Werkstudenten, die neben ihrem Studium arbeiten, sind in der Regel versicherungsfrei in der Kranken-, Pflege- und Arbeitslosenversicherung, wenn sie in der vorlesungsfreien Zeit nicht mehr als 20 Stunden pro Woche arbeiten. Sie sind jedoch in der Rentenversicherung pflichtversichert. Lohnsteuerrechtlich sollte die Besteuerung nach der Lohnsteuerkarte des Studenten erfolgen, und der Student muss sich selbst um eine studentische Krankenversicherung kümmern.\n","\n","Predicted Answer: Der L&P Unternehmens-Check ist der Einstieg in ein präzises Analyse- und Steuerungssystem für deinen Betrieb. Verbinde eine Standortbestimmung durch die Spezialisten von Lückel & Partner mit der Einführung digitaler Prozesse in deinem Unternehmen. Spezialisten liefern verständliche und aussagekräftige Zahlen und begleiten dich für einen nachhaltigen Erfolg in deinem Unternehmen. https://www.lup-beratung.de/unternehmens-check-holzbau\n","Predicted Category: Unternehmensberatung\n","Correct Answer: Der L&P Unternehmens-Check ist der Einstieg in ein präzises Analyse- und Steuerungssystem für deinen Betrieb. Verbinde eine Standortbestimmung durch die Spezialisten von Lückel & Partner mit der Einführung digitaler Prozesse in deinem Unternehmen. Spezialisten liefern verständliche und aussagekräftige Zahlen und begleiten dich für einen nachhaltigen Erfolg in deinem Unternehmen. https://www.lup-beratung.de/unternehmens-check-holzbau\n","Correct Category: Unternehmensberatung\n","Answer Prediction Confidence: 0.7799768447875977\n","Category Prediction Confidence: 0.9826366305351257\n","Der L&P Unternehmens-Check ist der Einstieg in ein präzises Analyse- und Steuerungssystem für deinen Betrieb. Verbinde eine Standortbestimmung durch die Spezialisten von Lückel & Partner mit der Einführung digitaler Prozesse in deinem Unternehmen. Spezialisten liefern verständliche und aussagekräftige Zahlen und begleiten dich für einen nachhaltigen Erfolg in deinem Unternehmen. https://www.lup-beratung.de/unternehmens-check-holzbau\n","\n","Predicted Answer: ('Unable to provide a confident answer:', 'Nein, die Stunden aus dem Arbeitszeitkonto im Baugewerbe dürfen nur zur Vermeidung von Saison-KUG verwendet werden. Es können aber bis zu 50 Stunden pro Jahr zur Überbrückung von Arbeitsausfällen außerhalb der Schlechtwetterzeit oder für Brücken- und Brauchtumstage geschützt werden.')\n","Predicted Category: Lohn\n","Correct Answer: Nein, der Urlaub wird mitgenommen zum neuen Arbeitgeber. Sollte der Mitarbeiter nicht mehr im Baugewerbe tätig werden, kann er nach 3 Monaten die Urlaubsabgeltung bei der Soka-Bau beantragen.\n","Correct Category: Lohn\n","Answer Prediction Confidence: 0.23090320825576782\n","Category Prediction Confidence: 0.8266445398330688\n","Bitte wenden Sie sich an Alexandra Himmelreich!\n","\n","Fertig.\n"]}]}]}